{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyCall\n",
    "using DataFrames\n",
    "\n",
    "# Import the Hugging Face Transformers library\n",
    "transformers    = pyimport(\"transformers\")\n",
    "torch           = pyimport(\"torch\")\n",
    "\n",
    "# Import the fine_tune_model and parse_decoded_strings functions from the Python script\n",
    "py\"\"\"\n",
    "import sys\n",
    "sys.path.append(\".\")\n",
    "from SGS_Tokenizers import BertTokenizerWrapper, RobertaTokenizerWrapper, GPT2TokenizerWrapper\n",
    "\"\"\"\n",
    "\n",
    "# Define the dataset\n",
    "texts = [\n",
    "    \"Hello, how are you?\",\n",
    "    \"Transformers are amazing!\",\n",
    "    \"Let's tokenize this text.\"\n",
    "]\n",
    "\n",
    "# Create a DataFrame to hold the text data\n",
    "df = DataFrame(text = texts)\n",
    "\n",
    "# Define a function to create batches\n",
    "function create_batches(df, batch_size)\n",
    "    batches = []\n",
    "    for i in 1:batch_size:size(df, 1)\n",
    "        push!(batches, df[i:min(i+batch_size-1, size(df, 1)), :])\n",
    "    end\n",
    "    return batches\n",
    "end\n",
    "\n",
    "# Create batches with a batch size of 2\n",
    "batches = create_batches(df, 2)\n",
    "\n",
    "# Instantiate a tokenizer wrapper (e.g., BERT)\n",
    "tokenizer = py\"RobertaTokenizerWrapper\"()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text data using the batches\n",
    "for batch in batches\n",
    "    for text in batch.text\n",
    "        tokens = tokenizer.tokenize(text)\n",
    "        println(\"Original Text: $text\")\n",
    "        println(\"Tokenized Tokens: $tokens\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CUDA\n",
    "\n",
    "# Check if the GPU is available\n",
    "if CUDA.has_cuda()\n",
    "    println(\"CUDA is available\")\n",
    "    println(\"Device: \", CUDA.device())\n",
    "else\n",
    "    println(\"CUDA is not available\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: done\n"
     ]
    }
   ],
   "source": [
    "using CUDA\n",
    "\n",
    "# Example: Move a tensor to the GPU and perform operations\n",
    "function gpu_example()\n",
    "    # Create a random tensor on the CPU\n",
    "    cpu_tensor = rand(Float32, 1000, 1000)\n",
    "    \n",
    "    # Move the tensor to the GPU\n",
    "    gpu_tensor = CUDA.fill(0.0f0, 10000, 10000)\n",
    "    CUDA.copyto!(gpu_tensor, cpu_tensor)\n",
    "    \n",
    "    # Perform operations on the GPU\n",
    "    gpu_result = gpu_tensor .+ 1.0f0\n",
    "    \n",
    "    # Move the result back to the CPU\n",
    "    cpu_result = Array(gpu_result)\n",
    "    \n",
    "    return cpu_result\n",
    "end\n",
    "\n",
    "result = gpu_example()\n",
    "println(\"Result: done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA runtime 12.5, artifact installation\n",
      "CUDA driver 12.6\n",
      "NVIDIA driver 560.35.3\n",
      "\n",
      "CUDA libraries: \n",
      "- CUBLAS: 12.6.1\n",
      "- CURAND: 10.3.6\n",
      "- CUFFT: 11.2.3\n",
      "- CUSOLVER: 11.6.3\n",
      "- CUSPARSE: 12.5.1\n",
      "- CUPTI: 2024.2.1 (API 23.0.0)\n",
      "- NVML: 12.0.0+560.35.3\n",
      "\n",
      "Julia packages: \n",
      "- CUDA: 5.4.3\n",
      "- CUDA_Driver_jll: 0.9.2+0\n",
      "- CUDA_Runtime_jll: 0.14.1+0\n",
      "\n",
      "Toolchain:\n",
      "- Julia: 1.10.4\n",
      "- LLVM: 15.0.7\n",
      "\n",
      "1 device:\n",
      "  0: Quadro M1200 (sm_50, 3.083 GiB / 4.000 GiB available)\n"
     ]
    }
   ],
   "source": [
    "CUDA.versioninfo()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
