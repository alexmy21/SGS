{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor_to_array (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using PyCall\n",
    "using DataFrames\n",
    "\n",
    "# Import the fine_tune_model and parse_decoded_strings functions from the Python script\n",
    "py\"\"\"\n",
    "import sys\n",
    "sys.path.append(\".\")\n",
    "from SGS_Tokenizer import ExtendedGPT2Tokenizer, GPT2Tokenizer, GPT2LMHeadModel\n",
    "\"\"\"\n",
    "\n",
    "function tensor_to_array(tensor::PyObject)\n",
    "    # Convert PyObject to Julia Vector{UInt32}\n",
    "    hllset_array = pycall(tensor.numpy, PyArray)\n",
    "    hllset_vector = Vector{Int64}(hllset_array)\n",
    "\n",
    "    return hllset_vector\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated double_value: 13.1\n",
      "Generated double_value: 1.4\n",
      "Generated double_value: 9.1\n",
      "Generated double_value: 0.1\n",
      "Generated double_value: 1.1\n",
      "Generated double_value: 5.3\n",
      "Generated double_value: 0.1\n",
      "Generated double_value: 9.2\n",
      "Generated double_value: 1.1\n",
      "Generated double_value: 2.2\n",
      "Generated double_value: 9.4\n",
      "Generated double_value: 5.2\n",
      "Generated double_value: 7.3\n",
      "Generated double_value: 1.4\n",
      "Generated double_value: 4.1\n",
      "Generated double_value: 15.1\n",
      "Generated double_value: 1.1\n",
      "Generated double_value: 5.4\n",
      "Generated double_value: 2.3\n",
      "Generated double_value: 3.1\n",
      "HLLSet:1; 4da9de3e80bcb65ee6169a411b0206ce45ba68bc; PyObject tensor([ 2, 18, 12,  2,  2, 28,  0,  8,  0, 22,  0,  0,  0,  2,  0,  2])\n",
      "Tensor Slice:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexmy/JULIA/SGS/SGS/venv/lib64/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyObject tensor([[1.0220e+03, 4.0546e+07, 1.0000e-01],\n",
      "        [1.2000e+01, 1.6594e+08, 1.0000e-01],\n",
      "        [7.3400e+02, 3.3153e+08, 1.1000e+00],\n",
      "        [3.0104e+04, 5.2051e+08, 1.1000e+00],\n",
      "        [5.1100e+02, 4.0169e+08, 1.1000e+00],\n",
      "        [2.6200e+02, 3.9209e+08, 1.4000e+00],\n",
      "        [2.6200e+02, 3.9209e+08, 1.4000e+00],\n",
      "        [3.1800e+02, 5.7578e+08, 2.2000e+00],\n",
      "        [3.5800e+03, 6.3241e+08, 2.3000e+00],\n",
      "        [7.8800e+02, 9.3641e+08, 3.1000e+00],\n",
      "        [4.1290e+03, 1.1767e+09, 4.1000e+00],\n",
      "        [2.8400e+02, 1.3680e+09, 5.2000e+00],\n",
      "        [4.3260e+03, 1.4954e+09, 5.3000e+00],\n",
      "        [1.5879e+04, 1.5664e+09, 5.4000e+00],\n",
      "        [3.0700e+02, 1.8849e+09, 7.3000e+00],\n",
      "        [5.2530e+03, 2.4650e+09, 9.1000e+00],\n",
      "        [1.3664e+04, 2.6029e+09, 9.2000e+00],\n",
      "        [5.4470e+03, 2.5253e+09, 9.4000e+00],\n",
      "        [2.2150e+03, 3.5021e+09, 1.3100e+01],\n",
      "        [2.8600e+02, 4.2398e+09, 1.5100e+01]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "text = \"When the distance between two unit-length vectors is defined to be the length of their vector difference then\"\n",
    "\n",
    "vocab_file = \"JLD2/vocab.json\"      # Path to the vocab file\n",
    "merges_file = \"JLD2/merges.txt\"     # Path to the merges file\n",
    "\n",
    "tokenizer = py\"ExtendedGPT2Tokenizer\"(vocab_file, merges_file, p=4)\n",
    "\n",
    "# text = \"When the distance between two unit-length vectors is defined to be the length of their vector difference then\"\n",
    "\n",
    "# Update tensors\n",
    "token_ids = tokenizer.tokenize_text(text)\n",
    "new_tensor_1, double_value = tokenizer.update_tensors(token_ids)\n",
    "\n",
    "# println(\"new_tensor_1:\", new_tensor_1)\n",
    "# println(\"double_value:\", double_value)\n",
    "\n",
    "id, sha1, hll_tensor = tokenizer.tensor_to_hlltensor(new_tensor_1)\n",
    "println(\"HLLSet:\", id, \"; \", sha1, \"; \", hll_tensor)\n",
    "\n",
    "hll_vector = tensor_to_array(hll_tensor)\n",
    "\n",
    "# println(\"HLLSet (Vector{Int64}):\", hll_vector)\n",
    "\n",
    "tensor_slice = tokenizer.hlltensor_to_tensor(hll_tensor)\n",
    "println(\"Tensor Slice:\", tensor_slice)\n",
    "\n",
    "# tokenizer.print_tensor_1(tensor=tokenizer.tensor_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_0: {'4da9de3e80bcb65ee6169a411b0206ce45ba68bc': 1}\n",
      "tensor_1:\n",
      "[2215,\t3502125683,\t13.1]\n",
      "[262,\t392093352,\t1.4]\n",
      "[5253,\t2464985007,\t9.1]\n",
      "[1022,\t40545897,\t0.1]\n",
      "[734,\t331532800,\t1.1]\n",
      "[4326,\t1495415092,\t5.3]\n",
      "[12,\t165936533,\t0.1]\n",
      "[13664,\t2602854234,\t9.2]\n",
      "[30104,\t520508673,\t1.1]\n",
      "[318,\t575781722,\t2.2]\n",
      "[5447,\t2525292680,\t9.4]\n",
      "[284,\t1368034586,\t5.2]\n",
      "[307,\t1884863212,\t7.3]\n",
      "[262,\t392093352,\t1.4]\n",
      "[4129,\t1176673453,\t4.1]\n",
      "[286,\t4239847945,\t15.1]\n",
      "[511,\t401687415,\t1.1]\n",
      "[15879,\t1566433000,\t5.4]\n",
      "[3580,\t632412124,\t2.3]\n",
      "[788,\t936414267,\t3.1]\n"
     ]
    }
   ],
   "source": [
    "tokenizer.print_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy_id: torch.Size([1, 1]); query_hllset: torch.Size([16])\n",
      "query_hllset_with_id: tensor([[ 0,  0,  0,  4,  4,  2,  0, 32, 16, 10,  0,  0,  2,  0,  0,  2,  2]])\n",
      "Related HLL sets: PyObject [0]\n",
      "Processing hllset (1): tensor([ 1,  2, 18, 12,  2,  2, 28,  0,  8,  0, 22,  0,  0,  0,  2,  0,  2])\n",
      "Processing hllset (2): tensor([ 2, 18, 12,  2,  2, 28,  0,  8,  0, 22,  0,  0,  0,  2,  0,  2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 01:48:30.721548: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-08 01:48:30.739676: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-08 01:48:30.746136: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-08 01:48:30.760620: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-08 01:48:31.973546: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PyObject [' between', '-', ' two', ' vectors', ' their', ' the', ' the', ' is', ' difference', ' then', ' length', ' to', ' unit', ' vector', ' be', ' distance', 'length', ' defined', 'When', ' of']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform search\n",
    "query = \"When the distance between two unit-length vectors is defined\"\n",
    "\n",
    "threshold = 0.1\n",
    "related_hllsets = pycall(tokenizer.search, PyObject, query, threshold)\n",
    "println(\"Related HLL sets: \", related_hllsets)\n",
    "\n",
    "# Get related tokens\n",
    "related_tokens = pycall(tokenizer.get_related_tokens, PyObject, related_hllsets)\n",
    "# println(\"Related tokens: \", related_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated text suggestions:\n",
      "Suggestion 1:\n",
      "-lengthWhenThis article is about a character, it is not about them. For other uses of the term \"character\", see Character (disambiguation).\n",
      "\n",
      "Suggestion 2:\n",
      "-lengthWhenThis article is about a character, it is not about them. For other uses of the term \"character\", see Character (disambiguation)\n",
      "\n",
      "Suggestion 3:\n",
      "-lengthWhenThis article is about a character, it is not about them. For other uses of the term \"character\", see Character.\n",
      "\n",
      "\"I'm\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexmy/JULIA/SGS/SGS/venv/lib64/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Generate meaningful text\n",
    "suggestions = []\n",
    "try    \n",
    "    suggestions = pycall(tokenizer.generate_text, PyObject, related_tokens, 3)\n",
    "catch e\n",
    "    println(\"Error generating text suggestions: \", e)\n",
    "end\n",
    "\n",
    "\n",
    "println(tokenizer.format_generated_texts(suggestions))\n",
    "\n",
    "# tokenizer.print_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hllset_id: 4da9de3e80bcb65ee6169a411b0206ce45ba68bc\n",
      "index: 1\n",
      "community_hllset: tensor([ 1,  2, 18, 12,  2,  2, 28,  0,  8,  0, 22,  0,  0,  0,  2,  0,  2])\n",
      "Evaluation results: \n",
      "Generated text suggestions:\n",
      "Suggestion 1:\n",
      "('-lengthWhenThis article is about a character, it is not about them. For other uses of the term \"character\", see Character (disambiguation).', '4da9de3e80bcb65ee6169a411b0206ce45ba68bc', 0.21087891921820445)\n",
      "\n",
      "Suggestion 2:\n",
      "('-lengthWhenThis article is about a character, it is not about them. For other uses of the term \"character\", see Character (disambiguation)', '4da9de3e80bcb65ee6169a411b0206ce45ba68bc', 0.2988664113443373)\n",
      "\n",
      "Suggestion 3:\n",
      "('-lengthWhenThis article is about a character, it is not about them. For other uses of the term \"character\", see Character.\\n\\n\"I\\'m', '4da9de3e80bcb65ee6169a411b0206ce45ba68bc', 0.29280576695787364)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate generated texts\n",
    "communities = [\n",
    "    \n",
    "    \"4da9de3e80bcb65ee6169a411b0206ce45ba68bc\"\n",
    "    ]  # Load or define your communities of HLL sets here\n",
    "\n",
    "evaluation_results = pycall(tokenizer.evaluate_generated_texts, PyObject, suggestions, communities)\n",
    "println(\"Evaluation results: \", tokenizer.format_generated_texts(evaluation_results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
