{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Main.HllGraph"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using Pkg\n",
    "# Pkg.add(\"PyCall\")\n",
    "# ENV[\"PYTHON\"] = \"/home/alexmy/JULIA/SGS/SGS/venv/bin/python\"\n",
    "# Pkg.build(\"PyCall\")\n",
    "include(\"src/graph.jl\")\n",
    "# include(\"src/sets.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using PyCall\n",
    "# pandas  = pyimport(\"pandas\")\n",
    "# redis   = pyimport(\"redis\")\n",
    "# sqlite  = pyimport(\"sqlite3\")\n",
    "# csv     = pyimport(\"csv\")\n",
    "\n",
    "csv_file_path = \"/home/alexmy/Downloads/POC/DATA/enron_05_17_2015_with_labels_v2.csv\"\n",
    "\n",
    "using CSV\n",
    "using DataFrames\n",
    "using WordTokenizers\n",
    "\n",
    "using ..HllGraph\n",
    "using ..HllSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HllSet{10}()\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    1. Message-ID\t\n",
    "    2. Date\t\n",
    "    3. From\t\n",
    "    4. To\t\n",
    "    5. Subject\t\n",
    "    6. X-From\tX-To\tX-cc\tX-bcc\tX-Folder\tX-Origin\tX-FileName\t\n",
    "    13. content\t\n",
    "    14. user\t\n",
    "    15. Cat_1_level_1\tCat_1_level_2\tCat_1_weight\tCat_2_level_1\tCat_2_level_2\tCat_2_weight\tCat_3_level_1\tCat_3_level_2\tCat_3_weight\tCat_4_level_1\tCat_4_level_2\tCat_4_weight\tCat_5_level_1\tCat_5_level_2\tCat_5_weight\tCat_6_level_1\tCat_6_level_2\tCat_6_weight\tCat_7_level_1\tCat_7_level_2\tCat_7_weight\tCat_8_level_1\tCat_8_level_2\tCat_8_weight\tCat_9_level_1\tCat_9_level_2\tCat_9_weight\tCat_10_level_1\tCat_10_level_2\tCat_10_weight\tCat_11_level_1\tCat_11_level_2\tCat_11_weight\tCat_12_level_1\tCat_12_level_2\tCat_12_weight\t\n",
    "    51. labeled\n",
    "\"\"\"\n",
    "\n",
    "df      = DataFrame(CSV.File(csv_file_path, header=true))\n",
    "df.From = map(x -> ismissing(x) ? \"\" : (isnothing(match(r\"'([^']*)'\", x)) ? \"\" : match(r\"'([^']*)'\", x).captures[1]), df.From)\n",
    "df.To   = map(x -> ismissing(x) ? \"\" : (isnothing(match(r\"'([^']*)'\", x)) ? \"\" : match(r\"'([^']*)'\", x).captures[1]), df.To)\n",
    "\n",
    "df_filled = coalesce.(df, \"unknown\")\n",
    "\n",
    "# Initialize sets to collect data from specific columns\n",
    "hll_03 = HllSets.HllSet{10}()     # Set{String}()\n",
    "hll_04 = HllSets.HllSet{10}()     # Set{String}()\n",
    "hll_05 = HllSets.HllSet{10}()     # Set{String}()\n",
    "hll_06 = HllSets.HllSet{10}()     # Set{String}()\n",
    "hll_14 = HllSets.HllSet{10}()     # Set{String}()\n",
    "hll_15 = HllSets.HllSet{10}()     # Set{String}()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "procecessed: 0 rows\n",
      "processed: 10001 rows in 158713 milliseconds seconds\n",
      "processed: 20002 rows in 156921 milliseconds seconds\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      "  [1] string(n::Int64; base::Int64, pad::Int64)",
      "    @ Base ./intfuncs.jl:881",
      "  [2] string",
      "    @ ./intfuncs.jl:881 [inlined]",
      "  [3] show",
      "    @ ./show.jl:1195 [inlined]",
      "  [4] print(io::IOBuffer, x::Int64)",
      "    @ Base ./strings/io.jl:35",
      "  [5] join(io::IOBuffer, iterator::Vector{Int64}, delim::String)",
      "    @ Base ./strings/io.jl:352",
      "  [6] join(io::IOBuffer, iterator::Vector{Int64})",
      "    @ Base ./strings/io.jl:349",
      "  [7] sprint(f::Function, args::Vector{Int64}; context::Nothing, sizehint::Int64)",
      "    @ Base ./strings/io.jl:114",
      "  [8] sprint",
      "    @ ./strings/io.jl:107 [inlined]",
      "  [9] join",
      "    @ ./strings/io.jl:356 [inlined]",
      " [10] bits_to_ints(vec::BitVector)",
      "    @ Main.HllSets ~/JULIA/SGS/SGS/src/sets.jl:506",
      " [11] dump(x::HllSet{10})",
      "    @ Main.HllSets ~/JULIA/SGS/SGS/src/sets.jl:433",
      " [12] top-level scope",
      "    @ ./In[4]:45"
     ]
    }
   ],
   "source": [
    "using Dates\n",
    "using Redis\n",
    "conn = Redis.RedisConnection()\n",
    "\n",
    "# # Read the CSV file\n",
    "i = 0\n",
    "total = 0\n",
    "println(\"procecessed: \", total, \" rows\")\n",
    "start_time = Dates.now()\n",
    "\n",
    "tokenized_csv_path = [String(s) for s in nltk_word_tokenize(csv_file_path)]\n",
    "file = HllGraph.create_node(tokenized_csv_path, \"node,file\")\n",
    "file_sha1 = file.sha1\n",
    "HllGraph.set_node(conn, file, \"b\")\n",
    "\n",
    "pipeline = open_pipeline(conn)\n",
    "\n",
    "for row in eachrow(df_filled)\n",
    "    hll_row = HllSets.HllSet{10}() \n",
    "    \n",
    "    row_3 = nltk_word_tokenize(row[3])\n",
    "    HllSets.add!(hll_03, row_3)    \n",
    "    HllSets.add!(hll_row, row_3) \n",
    "\n",
    "    row_4 = nltk_word_tokenize(row[4])\n",
    "    HllSets.add!(hll_04, row_4) \n",
    "    HllSets.add!(hll_row, row_4)\n",
    "\n",
    "    row_5 = nltk_word_tokenize(row[5])\n",
    "    HllSets.add!(hll_05, row_5)\n",
    "    HllSets.add!(hll_row, row_5) \n",
    "\n",
    "    row_6 = nltk_word_tokenize(row[6])\n",
    "    HllSets.add!(hll_06, row_6)\n",
    "    HllSets.add!(hll_row, row_6) \n",
    "\n",
    "    row_14 = nltk_word_tokenize(row[14])\n",
    "    HllSets.add!(hll_14, row_14) \n",
    "    HllSets.add!(hll_row, row_14) \n",
    "\n",
    "    row_15 = nltk_word_tokenize(row[15])\n",
    "    HllSets.add!(hll_15, row_15)\n",
    "    HllSets.add!(hll_row, row_15)\n",
    "\n",
    "    row_node = HllGraph.Node(HllSets.id(hll_row), \"node,row,$file_sha1\", HllSets.dump(hll_row))\n",
    "    key_name, node_dict = HllGraph.set_node(conn, row_node, \"b\", true)\n",
    "\n",
    "    Redis.hmset(pipeline, key_name, node_dict)\n",
    "\n",
    "    i += 1\n",
    "    if i > 10000\n",
    "        responses = read_pipeline(pipeline)\n",
    "        pipeline = open_pipeline(conn)\n",
    "        total += i\n",
    "        end_time = Dates.now()\n",
    "        println(\"processed: \", total, \" rows in \", end_time - start_time, \" seconds\")\n",
    "        start_time = Dates.now()\n",
    "        i = 0\n",
    "    end\n",
    "end\n",
    "\n",
    "responses = read_pipeline(pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "node2 = HllGraph.Node(HllSets.id(hll_02), \"node,column\", HllSets.dump(hll_02))\n",
    "HllGraph.set_node(conn, node2, \"b\")\n",
    "\n",
    "node3 = HllGraph.Node(HllSets.id(hll_03), \"node,column\", HllSets.dump(hll_03))\n",
    "HllGraph.set_node(conn, node3, \"b\")\n",
    "\n",
    "node4 = HllGraph.Node(HllSets.id(hll_04), \"node,column\", HllSets.dump(hll_04))\n",
    "HllGraph.set_node(conn, node4, \"b\")\n",
    "\n",
    "node5 = HllGraph.Node(HllSets.id(hll_05), \"node,column\", HllSets.dump(hll_05))\n",
    "HllGraph.set_node(conn, node5, \"b\")\n",
    "\n",
    "node13 = HllGraph.Node(HllSets.id(hll_13), \"node,column\", HllSets.dump(hll_13))\n",
    "HllGraph.set_node(conn, node13, \"b\")\n",
    "\n",
    "node14 = HllGraph.Node(HllSets.id(hll_14), \"node,column\", HllSets.dump(hll_14))\n",
    "HllGraph.set_node(conn, node14, \"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(length(Set(set_02)))\n",
    "println(Set(set_02))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
