{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGS simulation using Enron emails as a source. Day-by-day processing\n",
    "\n",
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module HllSets.\n",
      "WARNING: replacing module Util.\n",
      "WARNING: replacing module Entity.\n",
      "WARNING: replacing module Store.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "process_dataframe (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"src/sgs_store.jl\")\n",
    "\n",
    "# Import necessary packages\n",
    "using PyCall\n",
    "using DataFrames\n",
    "# import polars as pl\n",
    "using Dates\n",
    "using CSV\n",
    "\n",
    "# Import the fine_tune_model and parse_decoded_strings functions from the Python script\n",
    "py\"\"\"\n",
    "import sys\n",
    "sys.path.append(\".\")\n",
    "from SGS_Transformers import BertTokenizerWrapper, RobertaTokenizerWrapper, GPT2TokenizerWrapper\n",
    "\"\"\"\n",
    "\n",
    "redis   = pyimport(\"redis\")\n",
    "\n",
    "# Define a function to initialize the tokenizer\n",
    "function initialize_tokenizer()\n",
    "    return py\"RobertaTokenizerWrapper\"()\n",
    "end\n",
    "\n",
    "# Define a function to filter the DataFrame by date\n",
    "function filter_dataframe_by_date(df, date)\n",
    "    return df[df.Date .== date, :]\n",
    "end\n",
    "\n",
    "# Define a function to process each column\n",
    "function process_column(r, tokenizer, filtered_df, column, _parent, chunk_size)\n",
    "    col_values  = filtered_df[:, column]\n",
    "    col_sha1    = Util.sha1_union([_parent, string(column)])\n",
    "    column_size = Base.summarysize(col_values)\n",
    "    num_chunks  = ceil(Int, column_size / chunk_size)\n",
    "    chunks      = Store.chunk_array(col_values, num_chunks)\n",
    "\n",
    "    println(col_sha1, \"; num_chunks: \", num_chunks)\n",
    "    dataset = Store.ingest_df_column(r, tokenizer, chunks, col_sha1)\n",
    "    dataset_vector = Vector{UInt32}(dataset)\n",
    "\n",
    "    hll = HllSets.HllSet{10}()\n",
    "    _hll = HllSets.restore!(hll, dataset_vector)\n",
    "    \n",
    "    println(\"hll: \", HllSets.id(_hll), \"; \", HllSets.count(_hll))\n",
    "    \n",
    "    entity = Entity.Instance{10}(r, _hll, prefix=\"b:col\")\n",
    "    \n",
    "    return entity\n",
    "end\n",
    "\n",
    "# Define a function to process each column\n",
    "function process_row(r, tokenizer, filtered_df, _parent)\n",
    "    col_sha1    = Util.sha1_union([_parent])\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for row in eachrow(filtered_df)\n",
    "        # Join column values by space\n",
    "        row_str = join(row, \" \")\n",
    "        push!(rows, row_str)\n",
    "    end\n",
    "        \n",
    "    dataset = Store.ingest_df_rows(r, tokenizer, rows, col_sha1)\n",
    "    # dataset_vector = Vector{UInt32}(dataset)\n",
    "\n",
    "    hll = HllSets.HllSet{10}()\n",
    "    # _hll = HllSets.restore!(hll, dataset_vector)\n",
    "    \n",
    "    # println(\"hll: \", HllSets.id(_hll), \"; \", HllSets.count(_hll))\n",
    "    \n",
    "    entity = Entity.Instance{10}(r, hll, prefix=\"b:row\")\n",
    "    \n",
    "    return entity\n",
    "end\n",
    "\n",
    "# Define a function to process the DataFrame\n",
    "function process_dataframe(r, start, tokenizer, df, dates_vector, cols, _parent, chunk_size, threshold, batch)\n",
    "    i = start\n",
    "    while true && i < length(dates_vector)\n",
    "        the_date = dates_vector[i]\n",
    "        filtered_df = filter_dataframe_by_date(df, the_date)\n",
    "\n",
    "        for column in cols\n",
    "            entity = process_column(r, tokenizer, filtered_df, column, _parent, chunk_size)\n",
    "            println(\"Current Date:\", the_date)\n",
    "        end\n",
    "\n",
    "        process_row(r, tokenizer, filtered_df, _parent)\n",
    "\n",
    "        i += 1\n",
    "        # println(\"i = \", i)\n",
    "        if i > threshold\n",
    "            threshold += batch\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    return i, threshold\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Main function to run the demo\n",
    "function main(csv_file_path::String, start, chunk_size, threshold, batch)\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = initialize_tokenizer()\n",
    "\n",
    "    # Define other necessary variables\n",
    "    r = redis.Redis(host=\"localhost\", port=6379, db=0)  # Redis connection or other necessary setup\n",
    "    df = DataFrame(CSV.File(csv_file_path, header=true, select=[:Date, :From, :To, :Subject, :content, :user]))\n",
    "\n",
    "    # Reformat fields :Date, f:From, and :To\n",
    "    df.Date = map(x -> Dates.format(Dates.DateTime(x, \"yyyy-mm-dd HH:MM:SS\"), \"yyyy-mm-dd\"), df.Date)\n",
    "    df.From = map(x -> ismissing(x) ? \"\" : (isnothing(match(r\"'([^']*)'\", x)) ? \"\" : match(r\"'([^']*)'\", x).captures[1]), df.From)\n",
    "    df.To   = map(x -> ismissing(x) ? \"\" : (isnothing(match(r\"'([^']*)'\", x)) ? \"\" : match(r\"'([^']*)'\", x).captures[1]), df.To)\n",
    "    \n",
    "    # Extract distinct dates from the Date column, order them in ascending order, and convert to a vector\n",
    "    distinct_dates  = unique(df.Date)\n",
    "    sorted_dates    = sort(distinct_dates)    \n",
    "    dates_vector    = collect(sorted_dates)\n",
    "\n",
    "    cols        = [:From, :To, :Subject, :content, :user]\n",
    "    _parent     = csv_file_path\n",
    "    chunk_size  = chunk_size\n",
    "    threshold   = threshold\n",
    "    batch       = batch\n",
    "\n",
    "    # Process the DataFrame\n",
    "    return process_dataframe(r, start, tokenizer, df, dates_vector, cols, _parent, chunk_size, threshold, batch)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file_path = \"/home/alexmy/Downloads/POC/DATA/enron_05_17_2015_with_labels_v2.csv\"\n",
    "chunk_size = 512000\n",
    "threshold = 10\n",
    "batch = 10\n",
    "start = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6f983ba3758e7233f7379a9c7b6ee565808a8de6; num_chunks: 1\n",
      "hll: 280bd93a63b5f3227fa7dee132a1fb01e4fd6d0a; 3\n",
      "Current Date:1997-03-20\n",
      "6bc47f481f9b458cf32e52dbd4d6731a5d198af5; num_chunks: 1\n",
      "hll: 1ceaf73df40e531df3bfb26b4fb7cd95fb7bff1d; 1\n",
      "Current Date:1997-03-20\n",
      "f6c9fedfe796b71638efc125e924040013ef5234; num_chunks: 1\n",
      "hll: 4563ee72b0c3d9ed432b3ad0385272e6c2389584; 2\n",
      "Current Date:1997-03-20\n",
      "65875368cc6392683f42a0e2938b5c0789485b97; num_chunks: 1\n",
      "hll: 53925a473f0762909c3165d3a8c691d93b1e771b; 9\n",
      "Current Date:1997-03-20\n",
      "981f459d81197edf542958361ef219372da6bd82; num_chunks: 1\n",
      "hll: 1ceaf73df40e531df3bfb26b4fb7cd95fb7bff1d; 1\n",
      "Current Date:1997-03-20\n",
      "processing row . . .\n",
      "6f983ba3758e7233f7379a9c7b6ee565808a8de6; num_chunks: 1\n",
      "hll: 280bd93a63b5f3227fa7dee132a1fb01e4fd6d0a; 3\n",
      "Current Date:1997-03-21\n",
      "6bc47f481f9b458cf32e52dbd4d6731a5d198af5; num_chunks: 1\n",
      "hll: 1ceaf73df40e531df3bfb26b4fb7cd95fb7bff1d; 1\n",
      "Current Date:1997-03-21\n",
      "f6c9fedfe796b71638efc125e924040013ef5234; num_chunks: 1\n",
      "hll: c619f6775b6d919e0f3b2fe6f72ad2c3fc2126ad; 6\n",
      "Current Date:1997-03-21\n",
      "65875368cc6392683f42a0e2938b5c0789485b97; num_chunks: 1\n",
      "hll: 58064a93bf0f8147e3759f4af6116e3c7e591aba; 6\n",
      "Current Date:1997-03-21\n",
      "981f459d81197edf542958361ef219372da6bd82; num_chunks: 1\n",
      "hll: 1ceaf73df40e531df3bfb26b4fb7cd95fb7bff1d; 1\n",
      "Current Date:1997-03-21\n",
      "processing row . . .\n",
      "6f983ba3758e7233f7379a9c7b6ee565808a8de6; num_chunks: 1\n",
      "hll: 280bd93a63b5f3227fa7dee132a1fb01e4fd6d0a; 3\n",
      "Current Date:1997-03-31\n",
      "6bc47f481f9b458cf32e52dbd4d6731a5d198af5; num_chunks: 1\n",
      "hll: 1ceaf73df40e531df3bfb26b4fb7cd95fb7bff1d; 1\n",
      "Current Date:1997-03-31\n",
      "f6c9fedfe796b71638efc125e924040013ef5234; num_chunks: 1\n",
      "hll: 1ceaf73df40e531df3bfb26b4fb7cd95fb7bff1d; 1\n",
      "Current Date:1997-03-31\n",
      "65875368cc6392683f42a0e2938b5c0789485b97; num_chunks: 1\n",
      "hll: 9e1e31f5dd99be6396e0115d54da9de76d425702; 3\n",
      "Current Date:1997-03-31\n",
      "981f459d81197edf542958361ef219372da6bd82; num_chunks: 1\n",
      "hll: 1ceaf73df40e531df3bfb26b4fb7cd95fb7bff1d; 1\n",
      "Current Date:1997-03-31\n",
      "processing row . . .\n",
      "6f983ba3758e7233f7379a9c7b6ee565808a8de6; num_chunks: 1\n",
      "hll: 280bd93a63b5f3227fa7dee132a1fb01e4fd6d0a; 3\n",
      "Current Date:1997-04-07\n",
      "6bc47f481f9b458cf32e52dbd4d6731a5d198af5; num_chunks: 1\n",
      "hll: 1ceaf73df40e531df3bfb26b4fb7cd95fb7bff1d; 1\n",
      "Current Date:1997-04-07\n",
      "f6c9fedfe796b71638efc125e924040013ef5234; num_chunks: 1\n",
      "hll: ff80fd00e2ad707c4ca68c8b90e282fb87329b8e; 5\n",
      "Current Date:1997-04-07\n",
      "65875368cc6392683f42a0e2938b5c0789485b97; num_chunks: 1\n",
      "hll: 5410ab767f4a13f374e91c45b5f47eb3e0efa38e; 10\n",
      "Current Date:1997-04-07\n",
      "981f459d81197edf542958361ef219372da6bd82; num_chunks: 1\n",
      "hll: 1ceaf73df40e531df3bfb26b4fb7cd95fb7bff1d; 1\n",
      "Current Date:1997-04-07\n",
      "processing row . . .\n",
      "6f983ba3758e7233f7379a9c7b6ee565808a8de6; num_chunks: 1\n",
      "hll: 280bd93a63b5f3227fa7dee132a1fb01e4fd6d0a; 3\n",
      "Current Date:1997-04-10\n",
      "6bc47f481f9b458cf32e52dbd4d6731a5d198af5; num_chunks: 1\n",
      "hll: 1ceaf73df40e531df3bfb26b4fb7cd95fb7bff1d; 1\n",
      "Current Date:1997-04-10\n",
      "f6c9fedfe796b71638efc125e924040013ef5234; num_chunks: 1\n",
      "hll: fbce4faeb41fbf9642690e96738f76ac55c493f9; 7\n",
      "Current Date:1997-04-10\n",
      "65875368cc6392683f42a0e2938b5c0789485b97; num_chunks: 1\n",
      "hll: 6b3240cdf91a169c63131008db4a48a186d83bc8; 20\n",
      "Current Date:1997-04-10\n",
      "981f459d81197edf542958361ef219372da6bd82; num_chunks: 1\n",
      "hll: 1ceaf73df40e531df3bfb26b4fb7cd95fb7bff1d; 1\n",
      "Current Date:1997-04-10\n",
      "processing row . . .\n",
      "6f983ba3758e7233f7379a9c7b6ee565808a8de6; num_chunks: 1\n",
      "hll: 280bd93a63b5f3227fa7dee132a1fb01e4fd6d0a; 3\n",
      "Current Date:1997-04-11\n",
      "6bc47f481f9b458cf32e52dbd4d6731a5d198af5; num_chunks: 1\n",
      "hll: 1ceaf73df40e531df3bfb26b4fb7cd95fb7bff1d; 1\n",
      "Current Date:1997-04-11\n",
      "f6c9fedfe796b71638efc125e924040013ef5234; num_chunks: 1\n",
      "hll: 1307b84e2445d8dac55ccba9fa50cc63e9445a9e; 12\n",
      "Current Date:1997-04-11\n",
      "65875368cc6392683f42a0e2938b5c0789485b97; num_chunks: 1\n",
      "hll: e9ca67a5c83f36b9fda74283f98e25e5a52958df; 6\n",
      "Current Date:1997-04-11\n",
      "981f459d81197edf542958361ef219372da6bd82; num_chunks: 1\n",
      "hll: 1ceaf73df40e531df3bfb26b4fb7cd95fb7bff1d; 1\n",
      "Current Date:1997-04-11\n",
      "processing row . . .\n",
      "6f983ba3758e7233f7379a9c7b6ee565808a8de6; num_chunks: 1\n",
      "hll: 280bd93a63b5f3227fa7dee132a1fb01e4fd6d0a; 3\n",
      "Current Date:1997-04-15\n",
      "6bc47f481f9b458cf32e52dbd4d6731a5d198af5; num_chunks: 1\n",
      "hll: 1ceaf73df40e531df3bfb26b4fb7cd95fb7bff1d; 1\n",
      "Current Date:1997-04-15\n",
      "f6c9fedfe796b71638efc125e924040013ef5234; num_chunks: 1\n",
      "hll: fff848c218844e513d99aee26fdad449c46e2472; 17\n",
      "Current Date:1997-04-15\n",
      "65875368cc6392683f42a0e2938b5c0789485b97; num_chunks: 1\n",
      "hll: db174bf8f3eca55f8c26e1b327156cfa49327952; 9\n",
      "Current Date:1997-04-15\n",
      "981f459d81197edf542958361ef219372da6bd82; num_chunks: 1\n",
      "hll: 1ceaf73df40e531df3bfb26b4fb7cd95fb7bff1d; 1\n",
      "Current Date:1997-04-15\n",
      "processing row . . .\n",
      "6f983ba3758e7233f7379a9c7b6ee565808a8de6; num_chunks: 1\n",
      "hll: 280bd93a63b5f3227fa7dee132a1fb01e4fd6d0a; 3\n",
      "Current Date:1997-04-17\n",
      "6bc47f481f9b458cf32e52dbd4d6731a5d198af5; num_chunks: 1\n",
      "hll: 1ceaf73df40e531df3bfb26b4fb7cd95fb7bff1d; 1\n",
      "Current Date:1997-04-17\n",
      "f6c9fedfe796b71638efc125e924040013ef5234; num_chunks: 1\n",
      "hll: 4edb871944e628dccfafbe4d73a74070fcb8ef6b; 10\n",
      "Current Date:1997-04-17\n",
      "65875368cc6392683f42a0e2938b5c0789485b97; num_chunks: 1\n",
      "hll: b6f81d54745d287635e804be886438d5cd72efe6; 16\n",
      "Current Date:1997-04-17\n",
      "981f459d81197edf542958361ef219372da6bd82; num_chunks: 1\n",
      "hll: 1ceaf73df40e531df3bfb26b4fb7cd95fb7bff1d; 1\n",
      "Current Date:1997-04-17\n",
      "processing row . . .\n",
      "6f983ba3758e7233f7379a9c7b6ee565808a8de6; num_chunks: 1\n",
      "hll: 280bd93a63b5f3227fa7dee132a1fb01e4fd6d0a; 3\n",
      "Current Date:1997-04-18\n",
      "6bc47f481f9b458cf32e52dbd4d6731a5d198af5; num_chunks: 1\n",
      "hll: 1ceaf73df40e531df3bfb26b4fb7cd95fb7bff1d; 1\n",
      "Current Date:1997-04-18\n",
      "f6c9fedfe796b71638efc125e924040013ef5234; num_chunks: 1\n",
      "hll: 1ceaf73df40e531df3bfb26b4fb7cd95fb7bff1d; 1\n",
      "Current Date:1997-04-18\n",
      "65875368cc6392683f42a0e2938b5c0789485b97; num_chunks: 1\n",
      "hll: d230a36c4bd4716461ba275b3cb25736944b1a04; 3\n",
      "Current Date:1997-04-18\n",
      "981f459d81197edf542958361ef219372da6bd82; num_chunks: 1\n",
      "hll: 1ceaf73df40e531df3bfb26b4fb7cd95fb7bff1d; 1\n",
      "Current Date:1997-04-18\n",
      "processing row . . .\n",
      "6f983ba3758e7233f7379a9c7b6ee565808a8de6; num_chunks: 1\n",
      "hll: 280bd93a63b5f3227fa7dee132a1fb01e4fd6d0a; 3\n",
      "Current Date:1997-04-25\n",
      "6bc47f481f9b458cf32e52dbd4d6731a5d198af5; num_chunks: 1\n",
      "hll: 1ceaf73df40e531df3bfb26b4fb7cd95fb7bff1d; 1\n",
      "Current Date:1997-04-25\n",
      "f6c9fedfe796b71638efc125e924040013ef5234; num_chunks: 1\n",
      "hll: 0d4d558f08f1cc11b52cbd62a823f01f826828ea; 3\n",
      "Current Date:1997-04-25\n",
      "65875368cc6392683f42a0e2938b5c0789485b97; num_chunks: 1\n",
      "hll: 4ed465154a9117e3fa6dedc92dd1e86ed98ecc7d; 25\n",
      "Current Date:1997-04-25\n",
      "981f459d81197edf542958361ef219372da6bd82; num_chunks: 1\n",
      "hll: 1ceaf73df40e531df3bfb26b4fb7cd95fb7bff1d; 1\n",
      "Current Date:1997-04-25\n",
      "processing row . . .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(21, 30)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start, threshold = main(csv_file_path, start, chunk_size, threshold, batch)\n",
    "start, threshold"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
